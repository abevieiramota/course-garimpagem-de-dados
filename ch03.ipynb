{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding Similar Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Applications of Near-Neighbor Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1.1 Jaccard Similarity of Sets\n",
    "\n",
    "$$Jaccard\\ Similarity = \\frac{|A\\cap B|}{|A\\cup B|}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jaccard_sim(a, b):\n",
    "    \n",
    "    return len(a.intersection(b)) / len(a.union(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection: {3, 4}\n",
      "Union: {1, 2, 3, 4, 5, 7, 8}\n",
      "Jaccard Similarity = 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "a = set([1, 2, 3, 4, 5])\n",
    "b = set([3, 4, 7, 8])\n",
    "\n",
    "a_intersection_b = a.intersection(b)\n",
    "a_union_b = a.union(b)\n",
    "\n",
    "print(\"Intersection: {0}\\nUnion: {1}\\nJaccard Similarity = {2}\".format(a_intersection_b, \n",
    "                                                                       a_union_b,\n",
    "                                                                       jaccard_sim(a, b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard distance: 0.7142857142857143\n",
      "Jaccard Similarity: 0.2857142857142857\n"
     ]
    }
   ],
   "source": [
    "# NLTK\n",
    "from nltk.metrics import *\n",
    "\n",
    "print(\"Jaccard Distance: {0}\\nJaccard Similarity: {1}\".format(\\\n",
    "                                                              jaccard_distance(a, b), \n",
    "                                                              jaccard_sim(a, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Similarity of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Collaborative Filtering as a Similar-Sets Problem\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "||**ver introduction to recommender systems**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# explicar\n",
    "def jaccard_bag_sim(a, b):\n",
    "    \n",
    "    intersection_sum = sum((a & b).values())\n",
    "    union_sum = sum(a.values()) + sum(b.values())\n",
    "    \n",
    "    return intersection_sum / union_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard Bag Similarity: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "a = Counter('aaab')\n",
    "b = Counter('aabbc')\n",
    "\n",
    "print(\"Jaccard Bag Similarity: {}\".format(jaccard_bag_sim(a, b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Shingling of Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1 k-Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('H', 'e'), ('e', 'l'), ('l', 'l'), ('l', 'o'), ('o', ' '), (' ', 'W'), ('W', 'o'), ('o', 'r'), ('r', 'l'), ('l', 'd')]\n",
      "['Hel', 'ell', 'llo', 'lo ', 'o W', ' Wo', 'Wor', 'orl', 'rld']\n"
     ]
    }
   ],
   "source": [
    "# character ngram\n",
    "s = \"Hello World\"\n",
    "\n",
    "print(list(ngrams(s, 2)))\n",
    "print([''.join(i) for i in ngrams(s, 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('A', 'disciplina'), ('disciplina', 'Garimpagem'), ('Garimpagem', 'de'), ('de', 'Dados'), ('Dados', 'possui'), ('possui', '4'), ('4', 'créditos')]\n",
      "['A disciplina Garimpagem', 'disciplina Garimpagem de', 'Garimpagem de Dados', 'de Dados possui', 'Dados possui 4', 'possui 4 créditos']\n"
     ]
    }
   ],
   "source": [
    "# string ngram\n",
    "s = \"A disciplina Garimpagem de Dados possui 4 créditos\"\n",
    "\n",
    "print(list(ngrams(s.split(), 2)))\n",
    "print([' '.join(i) for i in ngrams(s.split(), 3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run books.py\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import re\n",
    "import nltk.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O meu fim evidente era atar as duas pontas da vida, e restaurar na velhice a adolescência.',\n",
       " 'Pois, senhor, não consegui recompor o que foi nem o que fui.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dom_casmurro[35:37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O homenzinho era uma pérola de bom, uma  pérola de gravata, tinha a voz grossa e dizia de dentro do bolso: \"Majestade Joana, podeis me  escutardes um minuto, só um minuto podereis interromperdes vossa sempre ocupação?\"',\n",
       " 'E  declarava depois: \"Sou vosso servo, princesa.']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perto_coracao[55:57]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 62136\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(analyzer='word', # n-gram de words\n",
    "                     ngram_range=(2, 2)) # 2-gram\n",
    "\n",
    "cv.fit(dom_casmurro + perto_coracao)\n",
    "\n",
    "print(\"Tamanho do vocabulário: {}\".format(len(cv.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linha:\n",
      "['O meu fim evidente era atar as duas pontas da vida, e restaurar na velhice a adolescência.']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>as duas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>atar as</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>da vida</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duas pontas</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>era atar</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evidente era</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fim evidente</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meu fim</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>na velhice</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pontas da</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>restaurar na</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>velhice adolescência</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vida restaurar</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      count\n",
       "as duas                   1\n",
       "atar as                   1\n",
       "da vida                   1\n",
       "duas pontas               1\n",
       "era atar                  1\n",
       "evidente era              1\n",
       "fim evidente              1\n",
       "meu fim                   1\n",
       "na velhice                1\n",
       "pontas da                 1\n",
       "restaurar na              1\n",
       "velhice adolescência      1\n",
       "vida restaurar            1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "line = dom_casmurro[35:36]\n",
    "cv_bigrams = cv.transform(line)\n",
    "df_cv_bigrams = pd.DataFrame(cv_bigrams.todense(), columns=cv.get_feature_names(), index=['count']).T\n",
    "\n",
    "print(\"Linha:\\n{}\".format(line))\n",
    "df_cv_bigrams[df_cv_bigrams['count'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from scipy import sparse\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dom_casmurro = cv.transform(dom_casmurro)\n",
    "y_dom_casmurro = np.zeros((X_dom_casmurro.shape[0], 1))\n",
    "X_perto_coracao = cv.transform(perto_coracao)\n",
    "y_perto_coracao = np.ones((X_perto_coracao.shape[0], 1))\n",
    "\n",
    "X = sparse.vstack((X_dom_casmurro, X_perto_coracao))\n",
    "y = np.vstack((y_dom_casmurro, y_perto_coracao)).ravel()\n",
    "\n",
    "knn = KNeighborsClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.6,  0.4]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict_proba(cv.transform([\"A menina do meio do coração\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6652392947103275"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y, knn.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do vocabulário: 12472\n"
     ]
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', # n-gram de words\n",
    "                        stop_words = nltk.corpus.stopwords.words(\"portuguese\")) # desconsiderar stop words\n",
    "\n",
    "tfidf.fit(dom_casmurro + perto_coracao)\n",
    "\n",
    "print(\"Tamanho do vocabulário: {}\".format(len(tfidf.vocabulary_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_dom_casmurro = tfidf.transform(dom_casmurro)\n",
    "y_dom_casmurro = np.zeros((X_dom_casmurro.shape[0], 1))\n",
    "X_perto_coracao = tfidf.transform(perto_coracao)\n",
    "y_perto_coracao = np.ones((X_perto_coracao.shape[0], 1))\n",
    "\n",
    "X = sparse.vstack((X_dom_casmurro, X_perto_coracao))\n",
    "y = np.vstack((y_dom_casmurro, y_perto_coracao)).ravel()\n",
    "\n",
    "knn_tfidf = KNeighborsClassifier().fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70843828715365242"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y, knn_tfidf.predict(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2.3 Hashing Shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HashingVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.float64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, n_features=1048576, ngram_range=(2, 2),\n",
       "         non_negative=False, norm='l2', preprocessor=None, stop_words=None,\n",
       "         strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "         tokenizer=None)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv = HashingVectorizer(analyzer='word', # n-gram de words\n",
    "                     ngram_range=(2, 2)) # 2-gram\n",
    "\n",
    "hv.fit([dom_casmurro, perto_coracao])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hv_bigrams = hv.transform([dom_casmurro])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perto do Coração Selvagem vocabulary size: 0.582302 megabytes\n",
      "Dom Casmurro size: 0.750664 megabytes\n",
      "CountVectorizer vocabulary size: 2.621544 megabytes\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"Perto do Coração Selvagem vocabulary size: {0} megabytes\".format(sys.getsizeof(perto_coracao) / 10**6))\n",
    "print(\"Dom Casmurro size: {0} megabytes\".format(sys.getsizeof(dom_casmurro) / 10**6))\n",
    "print(\"CountVectorizer vocabulary size: {0} megabytes\".format(sys.getsizeof(cv.vocabulary_) / 10**6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Similarity-Preserving Summaries of Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1 Matrix Representation of Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  0.,  1.,  0.],\n",
       "       [ 0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  1.,  1.],\n",
       "       [ 1.,  0.,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "D = [{'a':1, 'd':1}, {'c': 1}, {'b': 1, 'd': 1, 'e': 1}, {'a': 1, 'c': 1, 'd': 1}]\n",
    "\n",
    "X = dv.fit_transform(D)\n",
    "X # diferente da notação no livro, os conjuntos ficam representados por linhas, e não colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'a': 1.0, 'd': 1.0},\n",
       " {'c': 1.0},\n",
       " {'b': 1.0, 'd': 1.0, 'e': 1.0},\n",
       " {'a': 1.0, 'c': 1.0, 'd': 1.0}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dv.inverse_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.2 Minhashing\n",
    "\n",
    "Ver: http://mccormickml.com/2015/06/12/minhash-tutorial-with-python-code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.3 Minhashing and Jaccard Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.4 Minhash Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.5 Computing Minhash Signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Locality-Sensitive Hashing for Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
